{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td_lfikL13Uv",
        "outputId": "313cb41c-63c1-4b30-da64-80eacb47aa01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# Define paths to your training and testing directories\n",
        "train_data_dir = '/content/drive/MyDrive/Car_dataset_final/Train'\n",
        "test_data_dir = '/content/drive/MyDrive/Car_dataset_final/Test'\n",
        "\n",
        "# Constants\n",
        "img_width, img_height = 224, 224\n",
        "num_epochs = 50\n",
        "batch_size = 32\n",
        "num_classes = len(os.listdir(train_data_dir))\n",
        "\n",
        "# Data Generators with Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Load DenseNet121 base model\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False)\n",
        "\n",
        "# Add custom classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Combine base model with custom layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze layers in base model except the last few\n",
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size,\n",
        "    callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
        "\n",
        "# Load the best model\n",
        "model = tf.keras.models.load_model('best_model.h5')\n",
        "\n",
        "# Predict function\n",
        "def predict_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_width, img_height))\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0  # Rescale to [0,1]\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "    brand_names = sorted(os.listdir(train_data_dir))\n",
        "    predicted_brand_name = brand_names[predicted_class_index]\n",
        "    return predicted_brand_name\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/content/drive/MyDrive/Car_dataset_final/Test/mercedes/30.jpg'  # Replace with the path to the image you want to predict\n",
        "predicted_brand_name = predict_image(image_path)\n",
        "print(\"Predicted brand name:\", predicted_brand_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xocWZUA_135l",
        "outputId": "ca7e4a35-c54e-4f96-be41-7ea3167b00d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 64 images belonging to 3 classes.\n",
            "Found 58 images belonging to 3 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.1313 - accuracy: 0.3125 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2/2 [==============================] - 54s 38s/step - loss: 3.1313 - accuracy: 0.3125 - val_loss: 4.0164 - val_accuracy: 0.2812 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 19s 12s/step - loss: 3.0357 - accuracy: 0.3750 - val_loss: 2.2863 - val_accuracy: 0.1875 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 18s 12s/step - loss: 1.0206 - accuracy: 0.5469 - val_loss: 0.6634 - val_accuracy: 0.7188 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 24s 16s/step - loss: 1.1758 - accuracy: 0.5156 - val_loss: 0.5940 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 19s 12s/step - loss: 0.9666 - accuracy: 0.6875 - val_loss: 0.5018 - val_accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 18s 12s/step - loss: 0.3784 - accuracy: 0.8438 - val_loss: 0.8193 - val_accuracy: 0.6562 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 18s 11s/step - loss: 0.3262 - accuracy: 0.8438 - val_loss: 0.8972 - val_accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 19s 12s/step - loss: 0.4189 - accuracy: 0.7812 - val_loss: 0.6940 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 18s 12s/step - loss: 0.2744 - accuracy: 0.9062 - val_loss: 0.8528 - val_accuracy: 0.6250 - lr: 2.0000e-04\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 19s 12s/step - loss: 0.2245 - accuracy: 0.9062 - val_loss: 0.4565 - val_accuracy: 0.8125 - lr: 2.0000e-04\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 18s 11s/step - loss: 0.1879 - accuracy: 0.9219 - val_loss: 0.4723 - val_accuracy: 0.7812 - lr: 2.0000e-04\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 18s 10s/step - loss: 0.2204 - accuracy: 0.9375 - val_loss: 0.5748 - val_accuracy: 0.7500 - lr: 2.0000e-04\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 17s 11s/step - loss: 0.1237 - accuracy: 0.9844 - val_loss: 0.5072 - val_accuracy: 0.7500 - lr: 2.0000e-04\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 17s 10s/step - loss: 0.1539 - accuracy: 0.9531 - val_loss: 0.4902 - val_accuracy: 0.7500 - lr: 4.0000e-05\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 19s 12s/step - loss: 0.1388 - accuracy: 0.9531 - val_loss: 0.3503 - val_accuracy: 0.8438 - lr: 4.0000e-05\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 17s 11s/step - loss: 0.1469 - accuracy: 0.9844 - val_loss: 0.4295 - val_accuracy: 0.8125 - lr: 4.0000e-05\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 17s 11s/step - loss: 0.1641 - accuracy: 0.9375 - val_loss: 0.4924 - val_accuracy: 0.7500 - lr: 4.0000e-05\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 22s 15s/step - loss: 0.1346 - accuracy: 0.9688 - val_loss: 0.5949 - val_accuracy: 0.6562 - lr: 4.0000e-05\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 23s 15s/step - loss: 0.1233 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.7812 - lr: 8.0000e-06\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 19s 11s/step - loss: 0.1340 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.7812 - lr: 8.0000e-06\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Predicted brand name: mercedes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage:\n",
        "image_path = '/content/drive/MyDrive/Car_dataset_final/Test/audi/27.jpg'  # Replace with the path to the image you want to predict\n",
        "predicted_brand_name = predict_image(image_path)\n",
        "print(\"Predicted brand name:\", predicted_brand_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm9PRIZP14WL",
        "outputId": "85ba599a-5d7a-4d35-f4bc-399762a1a14d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 160ms/step\n",
            "Predicted brand name: audi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o4kWBv5V4gRg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}